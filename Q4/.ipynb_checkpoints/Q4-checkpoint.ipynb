{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Wikitext 2 data loading code\n",
    "\n",
    "To help you move faster, here is the code to generate the dataloaders for each task\n",
    "\n",
    "#### Prereqs:\n",
    "1. Make sure you have 'wiki-news-300d-1M.vec' downloaded locally\n",
    "2. Make sure to have 'mnli_val.tsv' and 'mnli_train.tsv' locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import  MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torch import nn\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78274/78274 [02:04<00:00, 630.06it/s]\n",
      "100%|██████████| 78274/78274 [00:00<00:00, 131385.62it/s]\n",
      "100%|██████████| 8464/8464 [00:00<00:00, 46375.08it/s]\n",
      "100%|██████████| 9708/9708 [00:00<00:00, 130425.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 33178\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    embedding_size = 300\n",
    "    max_vocab_size = 35000\n",
    "    embedding_dict = np.random.randn(max_vocab_size+2, embedding_size)\n",
    "    all_train_tokens = []\n",
    "    i = 0\n",
    "    \n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        all_train_tokens.append(tokens[0])\n",
    "        embedding_dict[i+2] = list(map(float, tokens[1:]))\n",
    "        i += 1\n",
    "        if i == max_vocab_size:\n",
    "            break\n",
    "            \n",
    "    return embedding_dict, all_train_tokens\n",
    "  \n",
    "# download the vectors yourself\n",
    "fasttext_embedding_dict, all_fasttext_tokens = load_vectors('wiki-news-300d-1M.vec')\n",
    "  \n",
    "class LMDataset(Dataset):\n",
    "    def __init__(self, list_of_token_lists):\n",
    "        self.input_tensors = []\n",
    "        self.target_tensors = []\n",
    "\n",
    "        for sample in list_of_token_lists:\n",
    "            self.input_tensors.append(torch.tensor([sample[:-1]], dtype=torch.long))\n",
    "            self.target_tensors.append(torch.tensor([sample[1:]], dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_tensors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.input_tensors[idx], self.target_tensors[idx])\n",
    "\n",
    "\n",
    "def tokenize_dataset(datasets, dictionary):\n",
    "    tokenized_datasets = {}\n",
    "    for split, dataset in datasets.items():\n",
    "        _current_dictified = []\n",
    "        for l in tqdm(dataset):\n",
    "            l = ['<bos>'] + l + ['<eos>']\n",
    "            encoded_l = dictionary.encode_token_seq(l)\n",
    "            _current_dictified.append(encoded_l)\n",
    "        tokenized_datasets[split] = _current_dictified\n",
    "    return tokenized_datasets\n",
    "\n",
    "def tokenize_mnli_dataset(datasets, dictionary):\n",
    "    tokenized_datasets = {}\n",
    "    for split, dataset in datasets.items():\n",
    "        _current_dictified = []\n",
    "        for s1, s2 in tqdm(dataset):\n",
    "            s1 = ['<bos>'] + s1 + ['<eos>']\n",
    "            s2 = ['<bos>'] + s2 + ['<eos>']\n",
    "            encoded_s1 = dictionary.encode_token_seq(s1)            \n",
    "            encoded_s2 = dictionary.encode_token_seq(s2)\n",
    "            _current_dictified.append([encoded_s1, encoded_s2])\n",
    "        tokenized_datasets[split] = _current_dictified\n",
    "    return tokenized_datasets\n",
    "\n",
    "def pad_list_of_tensors(list_of_tensors, pad_token):\n",
    "    max_length = max([t.size(-1) for t in list_of_tensors])\n",
    "    padded_list = []\n",
    "    for t in list_of_tensors:\n",
    "        padded_tensor = torch.cat(\n",
    "            [t, torch.tensor([[pad_token] * (max_length - t.size(-1))], dtype=torch.long)], dim=-1)\n",
    "        padded_list.append(padded_tensor)\n",
    "\n",
    "    padded_tensor = torch.cat(padded_list, dim=0)\n",
    "    return padded_tensor\n",
    "\n",
    "\n",
    "def pad_collate_fn(pad_idx, batch):\n",
    "    input_list = [s[0] for s in batch]\n",
    "    target_list = [s[1] for s in batch]\n",
    "    input_tensor = pad_list_of_tensors(input_list, pad_idx)\n",
    "    target_tensor = pad_list_of_tensors(target_list, pad_idx)\n",
    "    return input_tensor, target_tensor\n",
    "\n",
    "\n",
    "def load_wikitext(data_dir):\n",
    "    import subprocess\n",
    "    filename = os.path.join(data_dir, 'wikitext2-sentencized.json')\n",
    "    if not os.path.exists(filename):\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        url = \"https://nyu.box.com/shared/static/9kb7l7ci30hb6uahhbssjlq0kctr5ii4.json\"\n",
    "        args = ['wget', '-O', filename, url]\n",
    "        subprocess.call(args)\n",
    "    raw_datasets = json.load(open(filename, 'r'))\n",
    "    for name in raw_datasets:\n",
    "        raw_datasets[name] = [x.split() for x in raw_datasets[name]]\n",
    "\n",
    "    if os.path.exists(os.path.join(data_dir, 'vocab.pkl')):\n",
    "        vocab = pickle.load(open(os.path.join(data_dir, 'vocab.pkl'), 'rb'))\n",
    "    else:\n",
    "        vocab = Dictionary(raw_datasets, include_valid=False)\n",
    "        pickle.dump(vocab, open(os.path.join(data_dir, 'vocab.pkl'), 'wb'))\n",
    "\n",
    "    tokenized_datasets = tokenize_dataset(raw_datasets, vocab)\n",
    "    datasets = {name: LMDataset(ds) for name, ds in tokenized_datasets.items()}\n",
    "    print(\"Vocab size: %d\" % (len(vocab)))\n",
    "    return raw_datasets, datasets, vocab\n",
    "\n",
    "\n",
    "class Dictionary(object):\n",
    "    def __init__(self, datasets, include_valid=False):\n",
    "        self.tokens = []\n",
    "        self.ids = {}\n",
    "        self.counts = {}\n",
    "        \n",
    "        # add special tokens\n",
    "        self.add_token('<bos>')\n",
    "        self.add_token('<eos>')\n",
    "        self.add_token('<pad>')\n",
    "        self.add_token('<unk>')\n",
    "        \n",
    "        for line in tqdm(datasets['train']):\n",
    "            for w in line:\n",
    "                self.add_token(w)\n",
    "                    \n",
    "        if include_valid is True:\n",
    "            for line in tqdm(datasets['valid']):\n",
    "                for w in line:\n",
    "                    self.add_token(w)\n",
    "                            \n",
    "    def add_token(self, w):\n",
    "        if w not in self.tokens:\n",
    "            self.tokens.append(w)\n",
    "            _w_id = len(self.tokens) - 1\n",
    "            self.ids[w] = _w_id\n",
    "            self.counts[w] = 1\n",
    "        else:\n",
    "            self.counts[w] += 1\n",
    "\n",
    "    def get_id(self, w):\n",
    "        return self.ids[w]\n",
    "    \n",
    "    def get_token(self, idx):\n",
    "        return self.tokens[idx]\n",
    "    \n",
    "    def decode_idx_seq(self, l):\n",
    "        return [self.tokens[i] for i in l]\n",
    "    \n",
    "    def encode_token_seq(self, l):\n",
    "        return [self.ids[i] if i in self.ids else self.ids['<unk>'] for i in l]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    " \n",
    "raw_datasets, datasets, vocab = load_wikitext(os.getcwd())\n",
    "\n",
    "data_loaders = {name: DataLoader(datasets[name], batch_size=32, shuffle=True,\n",
    "                                     collate_fn=lambda x: pad_collate_fn(vocab.get_id('<pad>'), x))\n",
    "                    for name in datasets}\n",
    "wk2_train_dataloader = data_loaders['train']\n",
    "wk2_val_dataloader = data_loaders['valid']\n",
    "wk2_test_dataloader = data_loaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIKITEXT 2 dataset statistics\n",
      "training samples:2447\n",
      "val samples:265\n",
      "test samples:304\n"
     ]
    }
   ],
   "source": [
    "print('WIKITEXT 2 dataset statistics')\n",
    "print(f'training samples:{len(wk2_train_dataloader)}')\n",
    "print(f'val samples:{len(wk2_val_dataloader)}')\n",
    "print(f'test samples:{len(wk2_test_dataloader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "## MNLI loading code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label_map = {'contradiction':0,'neutral':1,'entailment':2}\n",
    "import pandas as pd\n",
    "import io\n",
    "from collections import Counter\n",
    "\n",
    "def get_string_tokenized_data(data):\n",
    "    \n",
    "    tokenized_data_x = [];\n",
    "    y_labels = []\n",
    "    all_tokens = [];\n",
    "    \n",
    "    for i,x in enumerate(data):\n",
    "        label = x[2]\n",
    "        if label == 'nan':\n",
    "            continue\n",
    "        \n",
    "        label = y_label_map[label]\n",
    "        y_labels.append(label)\n",
    "        \n",
    "        dp = [x[0].split(), x[1].split()]\n",
    "        tokenized_data_x.append(dp)\n",
    "        all_tokens += (dp[0] + dp[1])\n",
    "        \n",
    "\n",
    "    return all_tokens, tokenized_data_x, y_labels\n",
    "        \n",
    "\n",
    "\n",
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data, token2id):\n",
    "    indices_data = []\n",
    "    for tokens1, tokens2 in tokens_data:\n",
    "        index_list1 = [token2id[token] if token in token2id else UNK_IDX for token in tokens1]\n",
    "        index_list2 = [token2id[token] if token in token2id else UNK_IDX for token in tokens2]\n",
    "        indices_data.append([index_list1, index_list2])\n",
    "    return indices_data\n",
    "  \n",
    "# convert token to id in the dataset\n",
    "def token2index_using_wikitext2_dict(tokens_data, vocab):\n",
    "    indices_data = []\n",
    "    for tokens1, tokens2 in tokens_data:\n",
    "        index_list1 = vocab.encode_token_seq(tokens1)\n",
    "        index_list2 = vocab.encode_token_seq(tokens2)\n",
    "        indices_data.append([index_list1, index_list2])\n",
    "    return indices_data\n",
    "\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(MAX_VOCAB_SIZE))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "#### Validation set (used as test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentence1  \\\n",
      "0  'Not entirely , ' I snapped , harsher than int...   \n",
      "1  cook and then the next time it would be my tur...   \n",
      "\n",
      "                                           sentence2          label      genre  \n",
      "0            I spoke more harshly than I wanted to .     entailment    fiction  \n",
      "1  I would cook and then the next turn would be h...  contradiction  telephone  \n"
     ]
    }
   ],
   "source": [
    "# LOAD VAL\n",
    "\n",
    "val_df = pd.read_csv('mnli_val.tsv', sep=\"\\t\")\n",
    "print(val_df.head(2))\n",
    "\n",
    "val_df  = np.array(val_df)\n",
    "val_df = val_df.astype(str)\n",
    "val_genre_list = val_df[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_data_x, val_data_y = get_string_tokenized_data(val_df)\n",
    "del val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---   \n",
    "#### Training set (used as training, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('mnli_train.tsv', sep=\"\\t\")\n",
    "\n",
    "train_df  = np.array(train_df)\n",
    "train_df = train_df.astype(str)\n",
    "train_genre_list = train_df[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_data_x, train_data_y = get_string_tokenized_data(train_df)\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:00<00:00, 66208.74it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 65097.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# token2id, id2token = build_vocab(all_fasttext_tokens)\n",
    "# train_data_indices = token2index_using_wikitext2_dict(train_data_x, vocab)\n",
    "# val_data_indices = token2index_using_wikitext2_dict(val_data_x, vocab)\n",
    "\n",
    "\n",
    "mnli_raw_datasets = {'train': train_data_x, 'val': val_data_x}\n",
    "mnli_tokenized_datasets = tokenize_mnli_dataset(mnli_raw_datasets, vocab)\n",
    "\n",
    "train_data_indices = mnli_tokenized_datasets['train']\n",
    "val_data_indices = mnli_tokenized_datasets['val']\n",
    "\n",
    "\n",
    "# double checking\n",
    "print('\\n')\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices)))\n",
    "\n",
    "# del train_data_x\n",
    "# del train_data_y\n",
    "# del val_data_x\n",
    "# del val_data_y\n",
    "del mnli_tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genre = list(set(val_genre_list));\n",
    "nb_classes = len(y_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 200\n",
    "class MNLIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_x, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens\n",
    "        @param target_list: list of newsgroup targets\n",
    "\n",
    "        \"\"\"\n",
    "        self.data_x = data_x;\n",
    "        self.target_list = target_list\n",
    "        \n",
    "        assert(len(data_x) == len(target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        prem_token_idx = self.data_x[key][0][:MAX_SENTENCE_LENGTH]\n",
    "        hyp_token_idx = self.data_x[key][1][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [prem_token_idx, hyp_token_idx, label]\n",
    "\n",
    "\n",
    "def encode_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    prem_data_list = []\n",
    "    hyp_data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    # print(\"collate batch: \", batch[0][0])\n",
    "    # batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        prem_padded_vec = np.pad(np.array(datum[0]),\n",
    "                                 pad_width=((0, MAX_SENTENCE_LENGTH - len(datum[0]))),\n",
    "                                 mode=\"constant\", constant_values=0)\n",
    "        hyp_padded_vec = np.pad(np.array(datum[1]),\n",
    "                                pad_width=((0, MAX_SENTENCE_LENGTH - len(datum[1]))),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        prem_data_list.append(prem_padded_vec)\n",
    "        hyp_data_list.append(hyp_padded_vec)\n",
    "    return [torch.from_numpy((np.array(prem_data_list))), torch.from_numpy(np.array(hyp_data_list)),\n",
    "            torch.LongTensor(label_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "nb_train_samples = int(0.95 * len(train_data_indices))\n",
    "nb_val_samples = len(train_data_indices) - nb_train_samples\n",
    "\n",
    "# train/val split\n",
    "train_val_dataset = MNLIDataset(train_data_indices, train_data_y)\n",
    "train_dataset, val_dataset = random_split(train_val_dataset, [nb_train_samples, nb_val_samples])\n",
    "\n",
    "# train loader\n",
    "train_mnli_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=encode_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "# val loader\n",
    "val_mnli_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=encode_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "# test loader\n",
    "test_dataset = MNLIDataset(val_data_indices, val_data_y)\n",
    "test_mnli_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=encode_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNLI dataset statistics\n",
      "training samples:594\n",
      "val samples:32\n",
      "test samples:157\n"
     ]
    }
   ],
   "source": [
    "print('MNLI dataset statistics')\n",
    "print(f'training samples:{len(train_mnli_loader)}')\n",
    "print(f'val samples:{len(val_mnli_loader)}')\n",
    "print(f'test samples:{len(test_mnli_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## BERT MNLI finetune datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data.processors.glue import MnliProcessor\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import argparse\n",
    "import tempfile\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    BertTokenizer\n",
    ")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert = BertModel.from_pretrained('bert-base-cased', output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = [\"CoLA\", \"SST\", \"MRPC\", \"QQP\", \"STS\", \"MNLI\", \"SNLI\", \"QNLI\", \"RTE\", \"WNLI\", \"diagnostic\"]\n",
    "TASK2PATH = {\n",
    "    \"CoLA\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FCoLA.zip?alt=media&token=46d5e637-3411-4188-bc44-5809b5bfb5f4\",  # noqa\n",
    "    \"SST\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8\",  # noqa\n",
    "    \"MRPC\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&token=ec5c0836-31d5-48f4-b431-7480817f1adc\",  # noqa\n",
    "    \"QQP\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQQP-clean.zip?alt=media&token=11a647cb-ecd3-49c9-9d31-79f8ca8fe277\",  # noqa\n",
    "    \"STS\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSTS-B.zip?alt=media&token=bddb94a7-8706-4e0d-a694-1109e12273b5\",  # noqa\n",
    "    \"MNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FMNLI.zip?alt=media&token=50329ea1-e339-40e2-809c-10c40afff3ce\",  # noqa\n",
    "    \"SNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSNLI.zip?alt=media&token=4afcfbb2-ff0c-4b2d-a09a-dbf07926f4df\",  # noqa\n",
    "    \"QNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQNLIv2.zip?alt=media&token=6fdcf570-0fc5-4631-8456-9505272d1601\",  # noqa\n",
    "    \"RTE\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FRTE.zip?alt=media&token=5efa7e85-a0bb-4f19-8ea2-9e1840f077fb\",  # noqa\n",
    "    \"WNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FWNLI.zip?alt=media&token=068ad0a0-ded7-4bd7-99a5-5e00222e0faf\",  # noqa\n",
    "    \"diagnostic\": [\n",
    "        \"https://storage.googleapis.com/mtl-sentence-representations.appspot.com/tsvsWithoutLabels%2FAX.tsv?GoogleAccessId=firebase-adminsdk-0khhl@mtl-sentence-representations.iam.gserviceaccount.com&Expires=2498860800&Signature=DuQ2CSPt2Yfre0C%2BiISrVYrIFaZH1Lc7hBVZDD4ZyR7fZYOMNOUGpi8QxBmTNOrNPjR3z1cggo7WXFfrgECP6FBJSsURv8Ybrue8Ypt%2FTPxbuJ0Xc2FhDi%2BarnecCBFO77RSbfuz%2Bs95hRrYhTnByqu3U%2FYZPaj3tZt5QdfpH2IUROY8LiBXoXS46LE%2FgOQc%2FKN%2BA9SoscRDYsnxHfG0IjXGwHN%2Bf88q6hOmAxeNPx6moDulUF6XMUAaXCSFU%2BnRO2RDL9CapWxj%2BDl7syNyHhB7987hZ80B%2FwFkQ3MEs8auvt5XW1%2Bd4aCU7ytgM69r8JDCwibfhZxpaa4gd50QXQ%3D%3D\",  # noqa\n",
    "        \"https://www.dropbox.com/s/ju7d95ifb072q9f/diagnostic-full.tsv?dl=1\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "MRPC_TRAIN = \"https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\"\n",
    "MRPC_TEST = \"https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt\"\n",
    "\n",
    "\n",
    "def download_and_extract(task, data_dir):\n",
    "    print(\"Downloading and extracting %s...\" % task)\n",
    "    data_file = \"%s.zip\" % task\n",
    "    urllib.request.urlretrieve(TASK2PATH[task], data_file)\n",
    "    with zipfile.ZipFile(data_file) as zip_ref:\n",
    "        zip_ref.extractall(data_dir)\n",
    "    os.remove(data_file)\n",
    "    print(\"\\tCompleted!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_and_extract('MNLI', '.')\n",
    "data_file = \"MNLI.zip\"\n",
    "with zipfile.ZipFile(data_file) as zip_ref:\n",
    "        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = MnliProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_mnli_bert_dataloaders():\n",
    "  # ----------------------\n",
    "  # TRAIN/VAL DATALOADERS\n",
    "  # ----------------------\n",
    "  train = processor.get_train_examples('MNLI')\n",
    "  features = convert_examples_to_features(train,\n",
    "                                          tokenizer,\n",
    "                                          label_list=['contradiction','neutral','entailment'],\n",
    "                                          max_length=128,\n",
    "                                          output_mode='classification',\n",
    "                                          pad_on_left=False,\n",
    "                                          pad_token=tokenizer.pad_token_id,\n",
    "                                          pad_token_segment_id=0)\n",
    "  train_dataset = TensorDataset(torch.tensor([f.input_ids for f in features], dtype=torch.long), \n",
    "                                torch.tensor([f.attention_mask for f in features], dtype=torch.long), \n",
    "                                torch.tensor([f.token_type_ids for f in features], dtype=torch.long), \n",
    "                                torch.tensor([f.label for f in features], dtype=torch.long))\n",
    "\n",
    "  nb_train_samples = int(0.95 * len(train_dataset))\n",
    "  nb_val_samples = len(train_dataset) - nb_train_samples\n",
    "\n",
    "  bert_mnli_train_dataset, bert_mnli_val_dataset = random_split(train_dataset, [nb_train_samples, nb_val_samples])\n",
    "\n",
    "  # train loader\n",
    "  train_sampler = RandomSampler(bert_mnli_train_dataset)\n",
    "  bert_mnli_train_dataloader = DataLoader(bert_mnli_train_dataset, sampler=train_sampler, batch_size=32)\n",
    "\n",
    "  # val loader\n",
    "  val_sampler = RandomSampler(bert_mnli_val_dataset)\n",
    "  bert_mnli_val_dataloader = DataLoader(bert_mnli_val_dataset, sampler=val_sampler, batch_size=32)\n",
    "\n",
    "\n",
    "  # ----------------------\n",
    "  # TEST DATALOADERS\n",
    "  # ----------------------\n",
    "  dev = processor.get_dev_examples('MNLI')\n",
    "  features = convert_examples_to_features(dev,\n",
    "                                          tokenizer,\n",
    "                                          label_list=['contradiction','neutral','entailment'],\n",
    "                                          max_length=128,\n",
    "                                          output_mode='classification',\n",
    "                                          pad_on_left=False,\n",
    "                                          pad_token=tokenizer.pad_token_id,\n",
    "                                          pad_token_segment_id=0)\n",
    "\n",
    "  bert_mnli_test_dataset = TensorDataset(torch.tensor([f.input_ids for f in features], dtype=torch.long), \n",
    "                                torch.tensor([f.attention_mask for f in features], dtype=torch.long), \n",
    "                                torch.tensor([f.token_type_ids for f in features], dtype=torch.long), \n",
    "                                torch.tensor([f.label for f in features], dtype=torch.long))\n",
    "\n",
    "  # test dataset\n",
    "  test_sampler = RandomSampler(bert_mnli_test_dataset)\n",
    "  bert_mnli_test_dataloader = DataLoader(bert_mnli_test_dataset, sampler=test_sampler, batch_size=32)\n",
    "  \n",
    "  return bert_mnli_train_dataloader, bert_mnli_val_dataloader, bert_mnli_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_mnli_train_dataloader, bert_mnli_val_dataloader, bert_mnli_test_dataloader = generate_mnli_bert_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "tensor([[  101,  1155,  1300,  ...,     0,     0,     0],\n",
      "        [  101,   146,  1455,  ...,     0,     0,     0],\n",
      "        [  101,  1247,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1192,  1431,  ...,     0,     0,     0],\n",
      "        [  101,  1105,  1115,  ...,     0,     0,     0],\n",
      "        [  101, 10288,  1107,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "for i,(a,b,c,d) in enumerate(bert_mnli_train_dataloader):\n",
    "    print(c)\n",
    "    print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /anaconda3/envs/ds1011/lib/python3.6/site-packages (2.0.0)\n",
      "Requirement already satisfied: regex in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from transformers) (2019.8.19)\n",
      "Requirement already satisfied: numpy in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from transformers) (1.17.1)\n",
      "Requirement already satisfied: sacremoses in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: boto3 in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from transformers) (1.9.245)\n",
      "Requirement already satisfied: tqdm in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from transformers) (4.35.0)\n",
      "Requirement already satisfied: requests in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: sentencepiece in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from transformers) (0.1.83)\n",
      "Requirement already satisfied: six in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.245 in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from boto3->transformers) (1.12.245)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from requests->transformers) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from requests->transformers) (1.25.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.245->boto3->transformers) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /anaconda3/envs/ds1011/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.245->boto3->transformers) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 100062.28B/s]\n",
      "100%|██████████| 440473133/440473133 [01:45<00:00, 4158007.97B/s]\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = \"bert-base-uncased\"\n",
    "bert = BertModel.from_pretrained(pretrained_weights, output_attentions=True)\n",
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "freeze_model(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTSequenceClassifier(nn.Module):\n",
    "    def __init__(self, bert, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.W = nn.Linear(bert.config.hidden_size, num_classes)\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        h, _, attn = self.bert(input_ids=input_ids, \n",
    "                               attention_mask=attention_mask, \n",
    "                               token_type_ids=token_type_ids)\n",
    "        h_cls = h[:, 0]\n",
    "        logits = self.W(h_cls)\n",
    "        return logits, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "model = BERTSequenceClassifier(bert, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cache = []\n",
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "else:\n",
    "    current_device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#fine_tune_model.to(current_device)\n",
    "#def freeze_model(model):\n",
    "#    for param in model.parameters():\n",
    "#        param.requires_grad = False\n",
    "#freeze_model(BERT_feature_extractor)\n",
    "\n",
    "#BERT_feature_extractor.to(current_device)\n",
    "model.to(current_device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.convert_tokens_to_ids(\"[PAD]\")).to(current_device)\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = bert_mnli_train_dataloader, bert_mnli_val_dataloader, bert_mnli_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(a,b,c,d) in enumerate(bert_mnli_train_dataloader):\n",
    "    #print(c)\n",
    "    #print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits,_ = model(a,b,c)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(logits.view(-1, logits.size(-1)), d.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0801644325256348"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.nn.functional.softmax(logits, dim=1)\n",
    "predicted = outputs.max(1, keepdim=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.eq(d.view_as(predicted).to(current_device)).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 avg train loss = 1.2094\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-677f419d02db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ds1011/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-11e7de916d00>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m      9\u001b[0m         h, _, attn = self.bert(input_ids=input_ids, \n\u001b[1;32m     10\u001b[0m                                \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                token_type_ids=token_type_ids)\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mh_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ds1011/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ds1011/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    623\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    624\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ds1011/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ds1011/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ds1011/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ds1011/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ds1011/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ds1011/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ds1011/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ds1011/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ds1011/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "plot_cache = []\n",
    "for epoch_number in range(5):\n",
    "    avg_loss=0\n",
    "    model.train()\n",
    "    train_log_cache = []\n",
    "    for i, (inp, attention_masks , token_type_ids ,target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inp = inp.to(current_device)\n",
    "        target = target.to(current_device)\n",
    "        logits, _ = model(inp,attention_masks,token_type_ids)\n",
    "\n",
    "        loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_log_cache.append(loss.item())\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            avg_loss = sum(train_log_cache)/len(train_log_cache)\n",
    "            print('Step {} avg train loss = {:.{prec}f}'.format(i, avg_loss, prec=4))\n",
    "            train_log_cache = []\n",
    "\n",
    "    #do valid\n",
    "    valid_losses = []\n",
    "    #model.eval()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for inp,(inp, attention_masks , token_type_ids ,target) in test_loader:\n",
    "          inp = inp.to(current_device)\n",
    "          target = target.to(current_device)\n",
    "          logits, _ = model(inp,attention_masks,token_type_ids)\n",
    "          \n",
    "          outputs = F.softmax(logits, dim=1)\n",
    "          predicted = outputs.max(1, keepdim=True)[1]\n",
    "          temp = predicted\n",
    "          total += target.size(0)\n",
    "          correct += predicted.eq(target.view_as(predicted).to(current_device)).sum().item()\n",
    "        print(\"val acc\",100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
